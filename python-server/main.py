"""
YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì„œë²„
Whisperì™€ yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ YouTube ì˜ìƒì˜ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
"""

import os
import tempfile
import shutil
from pathlib import Path
from typing import Optional
import logging
from dotenv import load_dotenv
import os
import subprocess
import json
import time

# .env.local íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆìŒ)
load_dotenv('../.env.local')

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, HttpUrl
from typing import List, Optional
# whisper import will be done conditionally later
import yt_dlp

from constants import (
    DEFAULT_WHISPER_MODEL,
    DEFAULT_FORMAT_WITH_SEGMENTS,
    DEFAULT_FORMAT_WITH_TIMESTAMPS,
    AUDIO_QUALITY,
    AUDIO_CODEC,
    SERVER_HOST,
    SERVER_PORT,
    ALLOWED_ORIGINS,
    DEFAULT_TIMEOUT_SECONDS,
    MAX_TIMEOUT_SECONDS,
    TIMEOUT_PER_MB_SECONDS
)
from gpu_utils import get_safe_device, log_device_info
from cache_manager import cache_manager
from naver_datalab import naver_datalab_service

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Whisper.cpp Metal ì§€ì› í™•ì¸
USE_WHISPER_CPP = False
whisper_cpp_module = None
whisper_cpp_instances = {}  # ëª¨ë¸ë³„ ì¸ìŠ¤í„´ìŠ¤ ìºì‹œ
try:
    from whisper_cpp_metal import WhisperCppMetal
    whisper_cpp_module = WhisperCppMetal
    USE_WHISPER_CPP = True
    logger.info("âœ… Whisper.cpp Metal í™œì„±í™”ë¨")
except Exception as e:
    logger.warning(f"âš ï¸ Whisper.cpp Metalì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    logger.info("ğŸ’¡ OpenAI Whisperë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")

# ì„œë²„ ì‹œì‘ ì‹œ ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥
log_device_info()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì„œë²„",
    description="YouTube ì˜ìƒì˜ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” API ì„œë²„",
    version="1.0.0"
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ëª¨ë¸
class TranscriptionRequest(BaseModel):
    youtube_url: HttpUrl
    model_size: Optional[str] = DEFAULT_WHISPER_MODEL
    format_with_timestamps: Optional[bool] = DEFAULT_FORMAT_WITH_TIMESTAMPS
    format_with_segments: Optional[bool] = DEFAULT_FORMAT_WITH_SEGMENTS

# ì‘ë‹µ ëª¨ë¸
class TranscriptionResponse(BaseModel):
    success: bool
    text: Optional[str] = None
    error: Optional[str] = None
    processing_time: Optional[float] = None
    audio_size_mb: Optional[float] = None
    audio_duration: Optional[float] = None
    download_time: Optional[float] = None
    transcription_time: Optional[float] = None
    from_cache: Optional[bool] = None

# Whisper ëª¨ë¸ ìºì‹œ
whisper_models = {}

def get_whisper_model(model_size: str = DEFAULT_WHISPER_MODEL):
    """Whisper ëª¨ë¸ì„ ê°€ì ¸ì˜¤ê±°ë‚˜ ìºì‹œì—ì„œ ë¡œë“œ (CPU ëª¨ë“œ)"""
    if model_size not in whisper_models:
        logger.info(f"Whisper ëª¨ë¸ ë¡œë”© ì¤‘: {model_size} (CPU ëª¨ë“œ)")
        
        try:
            import whisper
            whisper_models[model_size] = whisper.load_model(model_size, device="cpu")
            logger.info(f"Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {model_size} (CPU)")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    return whisper_models[model_size]

def download_audio(youtube_url: str, output_path: str) -> tuple[bool, dict]:
    """
    YouTube ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (ìºì‹œ ì§€ì›)
    
    Args:
        youtube_url: YouTube URL
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        (ì„±ê³µ ì—¬ë¶€, íŒŒì¼ ì •ë³´)
    """
    try:
        # 1. ìºì‹œì—ì„œ íŒŒì¼ í™•ì¸
        cached_file = cache_manager.get_cached_file(youtube_url)
        if cached_file:
            logger.info(f"ìºì‹œëœ íŒŒì¼ ì‚¬ìš©: {youtube_url}")
            
            # ìºì‹œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            import shutil
            temp_audio_file = output_path.replace('%(ext)s', 'mp3')
            shutil.copy2(cached_file, temp_audio_file)
            
            # íŒŒì¼ í¬ê¸° ê³„ì‚°
            file_size = os.path.getsize(temp_audio_file)
            file_size_mb = file_size / (1024 * 1024)
            
            # ìºì‹œ ë©”íƒ€ë°ì´í„°ì—ì„œ duration ê°€ì ¸ì˜¤ê¸°
            cache_key = cache_manager._generate_cache_key(youtube_url)
            duration = cache_manager.metadata.get(cache_key, {}).get('duration', 0)
            
            return True, {
                'file_path': temp_audio_file,
                'size_mb': file_size_mb,
                'duration': duration,
                'from_cache': True
            }
        
        # 2. ìºì‹œì— ì—†ìœ¼ë©´ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ
        logger.info(f"ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {youtube_url}")
        
        ydl_opts = {
            'format': 'bestaudio/best',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': AUDIO_CODEC,
                'preferredquality': AUDIO_QUALITY,
            }],
            'outtmpl': output_path,
            'quiet': True,
            'no_warnings': True
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # ë¨¼ì € ì •ë³´ë§Œ ê°€ì ¸ì˜¤ê¸°
            info = ydl.extract_info(youtube_url, download=False)
            duration = info.get('duration', 0)
            
            # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ
            ydl.download([youtube_url])
        
        # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸ (í™•ì¥ìê°€ mp3ë¡œ ë³€ê²½ë¨)
        audio_file = output_path.replace('%(ext)s', 'mp3')
        if os.path.exists(audio_file):
            # íŒŒì¼ í¬ê¸° ê³„ì‚°
            file_size = os.path.getsize(audio_file)
            file_size_mb = file_size / (1024 * 1024)
            
            # ìºì‹œì— ì €ì¥
            cache_manager.cache_file(youtube_url, audio_file, duration)
            
            logger.info(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {audio_file} ({file_size_mb:.2f}MB, {duration}ì´ˆ)")
            return True, {
                'file_path': audio_file,
                'size_mb': file_size_mb,
                'duration': duration,
                'from_cache': False
            }
        else:
            logger.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {audio_file}")
            return False, {}
            
    except Exception as e:
        logger.error(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False, {}

def format_time(seconds: float) -> str:
    """ì´ˆë¥¼ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes:02d}:{secs:02d}"

def format_transcription_text(text: str) -> str:
    """
    ìŒì„± ì¸ì‹ ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ ë¬¸ì¥ êµ¬ë¶„ìë¡œ ë¶„í• 
    sentences = []
    current_sentence = ""
    
    # ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œë¡œ ë¬¸ì¥ êµ¬ë¶„
    for char in text:
        current_sentence += char
        if char in ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ']:
            sentences.append(current_sentence.strip())
            current_sentence = ""
    
    # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ìˆë‹¤ë©´ ì¶”ê°€
    if current_sentence.strip():
        sentences.append(current_sentence.strip())
    
    # ë¹ˆ ë¬¸ì¥ ì œê±°í•˜ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°
    formatted_text = '\n'.join([s for s in sentences if s])
    
    return formatted_text

def format_transcription_with_segments(result: dict, with_timestamps: bool = False) -> str:
    """
    Whisper ê²°ê³¼ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ í¬ë§·íŒ…
    
    Args:
        result: Whisper transcribe ê²°ê³¼
        with_timestamps: ì‹œê°„ ì •ë³´ í¬í•¨ ì—¬ë¶€
        
    Returns:
        í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    if "segments" not in result:
        # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í¬ë§·íŒ… ì‚¬ìš©
        return format_transcription_text(result["text"].strip())
    
    formatted_lines = []
    
    for segment in result["segments"]:
        text = segment["text"].strip()
        if not text:
            continue
            
        if with_timestamps:
            start_time = format_time(segment["start"])
            end_time = format_time(segment["end"])
            line = f"[{start_time}-{end_time}] {text}"
        else:
            line = text
            
        formatted_lines.append(line)
    
    return '\n'.join(formatted_lines)

import signal
import threading
from contextlib import contextmanager

@contextmanager
def timeout_context(seconds):
    """íƒ€ì„ì•„ì›ƒ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    def timeout_handler(signum, frame):
        raise TimeoutError(f"ì‘ì—…ì´ {seconds}ì´ˆ í›„ íƒ€ì„ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤")
    
    # Unix ì‹œìŠ¤í…œì—ì„œë§Œ signal ì‚¬ìš©
    if hasattr(signal, 'SIGALRM'):
        old_handler = signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(seconds)
        try:
            yield
        finally:
            signal.alarm(0)
            signal.signal(signal.SIGALRM, old_handler)
    else:
        # Windowsë‚˜ ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œëŠ” ë‹¨ìˆœíˆ yield
        yield

def transcribe_audio(audio_path: str, model_size: str = DEFAULT_WHISPER_MODEL, format_with_segments: bool = DEFAULT_FORMAT_WITH_SEGMENTS, format_with_timestamps: bool = DEFAULT_FORMAT_WITH_TIMESTAMPS) -> Optional[str]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (íƒ€ì„ì•„ì›ƒ ë° ê°•í™”ëœ ì—ëŸ¬ ì²˜ë¦¬)
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        model_size: Whisper ëª¨ë¸ í¬ê¸°
        format_with_segments: ì„¸ê·¸ë¨¼íŠ¸ë³„ ì¤„ë°”ê¿ˆ ì—¬ë¶€
        format_with_timestamps: ì‹œê°„ ì •ë³´ í¬í•¨ ì—¬ë¶€
        
    Returns:
        ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None
    """
    try:
        logger.info(f"ìŒì„± ì¸ì‹ ì‹œì‘: {audio_path}")
        
        # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸
        if not os.path.exists(audio_path):
            # í™•ì¥ì ë³€ê²½ ì‹œë„
            audio_path = audio_path.replace('%(ext)s', 'mp3')
            if not os.path.exists(audio_path):
                logger.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {audio_path}")
                return None
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(audio_path)
        file_size_mb = file_size / (1024 * 1024)
        logger.info(f"ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f}MB")
        
        # íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í¬ë©´ ê²½ê³ 
        if file_size_mb > 100:  # 100MB ì´ìƒ
            logger.warning(f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë§¤ìš° í½ë‹ˆë‹¤: {file_size_mb:.2f}MB. ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # Whisper.cpp Metal ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        if USE_WHISPER_CPP:
            logger.info("ğŸš€ Whisper.cpp Metal ì‚¬ìš© (GPU ê°€ì†)")
            try:
                # ëª¨ë¸ë³„ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
                if model_size not in whisper_cpp_instances:
                    logger.info(f"Whisper.cpp {model_size} ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
                    # medium ëª¨ë¸ì´ ì†ìƒëœ ê²½ìš° large ëª¨ë¸ ì‚¬ìš©
                    actual_model = model_size
                    if model_size == "medium":
                        actual_model = "large-v3"
                        logger.warning(f"medium ëª¨ë¸ ëŒ€ì‹  {actual_model} ëª¨ë¸ ì‚¬ìš©")
                    whisper_cpp_instances[model_size] = whisper_cpp_module(model_size=actual_model)
                
                whisper_cpp = whisper_cpp_instances[model_size]
                
                # ìŒì„± ì¸ì‹ ì‹¤í–‰
                result = whisper_cpp.transcribe(
                    audio_path=audio_path,
                    language="ko",  # í•œêµ­ì–´ë¡œ ëª…ì‹œì  ì„¤ì •
                    no_timestamps=not format_with_timestamps
                )
                
                if result["success"]:
                    text = result["text"]
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ í¬ë§·íŒ…ì´ í•„ìš”í•œ ê²½ìš°
                    if format_with_segments and result.get("segments"):
                        segments = result["segments"]
                        if format_with_timestamps:
                            formatted_lines = []
                            for seg in segments:
                                if isinstance(seg, dict) and "text" in seg:
                                    start = seg.get("start", 0)
                                    end = seg.get("end", 0)
                                    text_content = seg["text"].strip()
                                    if text_content:
                                        formatted_lines.append(f"[{format_time(start)}-{format_time(end)}] {text_content}")
                                else:
                                    formatted_lines.append(str(seg))
                            text = '\n'.join(formatted_lines)
                        else:
                            text = '\n'.join([seg.get("text", "").strip() for seg in segments if isinstance(seg, dict)])
                    
                    logger.info(f"Whisper.cpp Metal ìŒì„± ì¸ì‹ ì™„ë£Œ: {len(text)} ë¬¸ì")
                    return text
                else:
                    logger.error(f"Whisper.cpp ì˜¤ë¥˜: {result.get('error', 'Unknown error')}")
                    # OpenAI Whisperë¡œ í´ë°±
                    logger.info("OpenAI Whisperë¡œ í´ë°±")
            except Exception as e:
                logger.error(f"Whisper.cpp ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                logger.info("OpenAI Whisperë¡œ í´ë°±")
        
        # CPU ëª¨ë“œë¡œ OpenAI Whisper ì‚¬ìš© (í´ë°± ë˜ëŠ” ê¸°ë³¸)
        logger.info("CPU ëª¨ë“œë¡œ OpenAI Whisper ì‚¬ìš©")
        model = get_whisper_model(model_size)
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì • (íŒŒì¼ í¬ê¸°ì— ë”°ë¼ ì¡°ì •)
        timeout_seconds = min(
            MAX_TIMEOUT_SECONDS,
            max(DEFAULT_TIMEOUT_SECONDS, int(file_size_mb * TIMEOUT_PER_MB_SECONDS))
        )
        logger.info(f"íƒ€ì„ì•„ì›ƒ ì„¤ì •: {timeout_seconds}ì´ˆ (íŒŒì¼ í¬ê¸°: {file_size_mb:.2f}MB)")
        
        # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ìŒì„± ì¸ì‹ ì‹¤í–‰
        with timeout_context(timeout_seconds):
            result = model.transcribe(audio_path)
        
        raw_text = result["text"].strip()
        
        # í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì ìš©
        if format_with_segments:
            formatted_text = format_transcription_with_segments(result, format_with_timestamps)
        else:
            formatted_text = format_transcription_text(raw_text)
        
        logger.info(f"OpenAI Whisper ìŒì„± ì¸ì‹ ì™„ë£Œ: {len(raw_text)} ë¬¸ì -> {len(formatted_text)} ë¬¸ì (í¬ë§·íŒ…ë¨)")
        return formatted_text
        
    except TimeoutError as e:
        logger.error(f"ìŒì„± ì¸ì‹ íƒ€ì„ì•„ì›ƒ: {str(e)}")
        return None
    except MemoryError as e:
        logger.error(f"ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}")
        return None
    except Exception as e:
        error_msg = str(e)
        logger.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {error_msg}")
        return None

def cleanup_files(file_path: str):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
            logger.info(f"íŒŒì¼ ì‚­ì œë¨: {file_path}")
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì„œë²„",
        "version": "1.0.0",
        "endpoints": {
            "POST /transcribe": "YouTube URLë¡œë¶€í„° ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ",
            "GET /health": "ì„œë²„ ìƒíƒœ í™•ì¸"
        }
    }

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    from gpu_utils import get_device_info
    
    device_info = get_device_info()
    
    # Whisper ëª¨ë“œ ì •ë³´
    whisper_info = {
        "mode": "Metal GPU" if USE_WHISPER_CPP else "CPU",
        "whisper_cpp": USE_WHISPER_CPP,
        "message": "Metal GPU ê°€ì† í™œì„±í™” (ê³ ì† ì²˜ë¦¬)" if USE_WHISPER_CPP else "CPU ëª¨ë“œë¡œ ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘",
        "loaded_models": list(whisper_cpp_instances.keys()) if USE_WHISPER_CPP else []
    }
    
    return {
        "status": "healthy", 
        "message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤ (CPU ëª¨ë“œ)",
        "device_info": device_info,
        "whisper": whisper_info
    }

@app.post("/transcribe", response_model=TranscriptionResponse)
async def transcribe_youtube_video(
    request: TranscriptionRequest,
    background_tasks: BackgroundTasks
):
    """
    YouTube ì˜ìƒì˜ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)
    
    Args:
        request: YouTube URLê³¼ ëª¨ë¸ í¬ê¸°
        background_tasks: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (íŒŒì¼ ì •ë¦¬ìš©)
        
    Returns:
        ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€
    """
    import time
    start_time = time.time()
    download_start_time = None
    transcription_start_time = None
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    temp_dir = tempfile.mkdtemp()
    audio_path = os.path.join(temp_dir, "audio.%(ext)s")
    
    try:
        # 1. YouTube URLì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        youtube_url = str(request.youtube_url)
        download_start_time = time.time()
        
        download_success, audio_info = download_audio(youtube_url, audio_path)
        if not download_success:
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        download_time = time.time() - download_start_time
        logger.info(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {download_time:.2f}ì´ˆ")
        
        # 2. ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        transcription_start_time = time.time()
        text = transcribe_audio(
            audio_path, 
            request.model_size,
            format_with_segments=request.format_with_segments,
            format_with_timestamps=request.format_with_timestamps
        )
        
        if text is None:
            raise HTTPException(status_code=500, detail="ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        transcription_time = time.time() - transcription_start_time
        total_time = time.time() - start_time
        
        logger.info(f"ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcription_time:.2f}ì´ˆ (ì´ {total_time:.2f}ì´ˆ)")
        
        # 3. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        background_tasks.add_task(cleanup_files, audio_path.replace('%(ext)s', 'mp3'))
        background_tasks.add_task(shutil.rmtree, temp_dir)
        
        return TranscriptionResponse(
            success=True,
            text=text,
            processing_time=total_time,
            audio_size_mb=audio_info.get('size_mb'),
            audio_duration=audio_info.get('duration'),
            download_time=download_time,
            transcription_time=transcription_time,
            from_cache=audio_info.get('from_cache', False)
        )
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except TimeoutError as e:
        logger.error(f"íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜: {str(e)}")
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        background_tasks.add_task(cleanup_files, audio_path.replace('%(ext)s', 'mp3'))
        background_tasks.add_task(shutil.rmtree, temp_dir)
        raise HTTPException(status_code=408, detail=f"ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤: {str(e)}")
    except MemoryError as e:
        logger.error(f"ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜: {str(e)}")
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        background_tasks.add_task(cleanup_files, audio_path.replace('%(ext)s', 'mp3'))
        background_tasks.add_task(shutil.rmtree, temp_dir)
        raise HTTPException(status_code=507, detail="ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ì‘ì€ íŒŒì¼ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
        logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        background_tasks.add_task(cleanup_files, audio_path.replace('%(ext)s', 'mp3'))
        background_tasks.add_task(shutil.rmtree, temp_dir)
        
        raise HTTPException(
            status_code=500, 
            detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.get("/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Whisper ëª¨ë¸ ëª©ë¡"""
    return {
        "models": [
            {"name": "medium", "description": "ë†’ì€ ì •í™•ë„, Metal ê°€ì† ì§€ì›"},
            {"name": "large", "description": "ìµœê³  ì •í™•ë„, Metal ê°€ì† ì§€ì› (large-v3)"}
        ],
        "loaded_models": list(whisper_models.keys())
    }

@app.get("/cache/info")
async def get_cache_info():
    """ìºì‹œ ì •ë³´ ì¡°íšŒ"""
    return cache_manager.get_cache_info()

@app.delete("/cache/clear")
async def clear_cache():
    """ëª¨ë“  ìºì‹œ ì‚­ì œ"""
    cache_manager.clear_all_cache()
    return {"message": "ëª¨ë“  ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}

# ë„¤ì´ë²„ ë°ì´í„°ë© ê´€ë ¨ ëª¨ë¸
class KeywordTrendRequest(BaseModel):
    keywords: List[str]
    start_date: Optional[str] = None
    end_date: Optional[str] = None

class KeywordTrendResponse(BaseModel):
    success: bool
    keywords: List[dict]
    error: Optional[str] = None

@app.post("/keywords/trends", response_model=KeywordTrendResponse)
async def get_keyword_trends(request: KeywordTrendRequest):
    """ë„¤ì´ë²„ ë°ì´í„°ë©ì—ì„œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        keywords = naver_datalab_service.get_search_trends(
            keywords=request.keywords,
            start_date=request.start_date,
            end_date=request.end_date
        )
        
        return KeywordTrendResponse(
            success=True,
            keywords=keywords
        )
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return KeywordTrendResponse(
            success=False,
            keywords=[],
            error=str(e)
        )

@app.get("/keywords/shopping")
async def get_shopping_insights():
    """ë„¤ì´ë²„ ì‡¼í•‘ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        keywords = naver_datalab_service.get_shopping_insights()
        return {
            "success": True,
            "keywords": keywords
        }
    except Exception as e:
        logger.error(f"ì‡¼í•‘ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "keywords": [],
            "error": str(e)
        }

@app.get("/keywords/mock")
async def get_mock_keyword_data():
    """ì‹œë®¬ë ˆì´ì…˜ëœ í‚¤ì›Œë“œ ë°ì´í„° ë°˜í™˜ (í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        keywords = naver_datalab_service._get_mock_trend_data([])
        return {
            "success": True,
            "keywords": keywords
        }
    except Exception as e:
        logger.error(f"ëª¨ì˜ í‚¤ì›Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "keywords": [],
            "error": str(e)
        }

@app.post("/keywords/related")
async def get_related_keywords(request: dict):
    """ë©”ì¸ í‚¤ì›Œë“œì™€ ê´€ë ¨ í‚¤ì›Œë“œì˜ íŠ¸ë Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        main_keyword = request.get("keyword", "")
        include_related = request.get("include_related", True)
        max_related = request.get("max_related", 10)
        
        if not main_keyword:
            return {"success": False, "error": "í‚¤ì›Œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."}
        
        keywords = naver_datalab_service.get_search_trends_with_related(
            main_keyword=main_keyword,
            include_related=include_related,
            max_related=max_related
        )
        
        return {"success": True, "keywords": keywords}
    except Exception as e:
        logger.error(f"ê´€ë ¨ í‚¤ì›Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {"success": False, "keywords": [], "error": str(e)}

# Claude CLI í‰ê°€ ìš”ì²­ ëª¨ë¸
class ContentEvaluationRequest(BaseModel):
    content: str
    title: Optional[str] = None
    category: Optional[str] = None
    evaluation_type: Optional[str] = "comprehensive"  # comprehensive, simple, category_specific

class ContentEvaluationResponse(BaseModel):
    success: bool
    evaluation: Optional[dict] = None
    error: Optional[str] = None
    processing_time: Optional[float] = None
    result: Optional[str] = None  # Claude CLIì˜ ì›ë³¸ í…ìŠ¤íŠ¸ ì‘ë‹µ

@app.post("/evaluate/content", response_model=ContentEvaluationResponse)
async def evaluate_content(request: ContentEvaluationRequest):
    """Claude CLIë¥¼ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  í‰ê°€"""
    import time
    start_time = time.time()
    
    try:
        
        # í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if request.evaluation_type == "simple":
            prompt = f"""ì½˜í…ì¸ : {request.content}

YouTube ì˜ìƒ ì½˜í…ì¸ ë¡œì„œ 1-10ì  í‰ê°€:
- ì¬ë¯¸ë„ (ì‹œì²­ìê°€ ì¬ë¯¸ìˆì–´í• ê¹Œ?)
- ì •ë³´ì„± (ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ê°€?)
- ë°”ì´ëŸ´ ê°€ëŠ¥ì„± (ê³µìœ í•˜ê³  ì‹¶ì€ ì½˜í…ì¸ ì¸ê°€?)
- ì œì‘ ë‚œì´ë„ (ì‹¤ì œ ë§Œë“¤ê¸° ì–´ë ¤ìš´ê°€?)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
        else:  # comprehensive
            prompt = f"""ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

ì½˜í…ì¸ : {request.content}
{f'ì œëª©: {request.title}' if request.title else ''}
{f'ì¹´í…Œê³ ë¦¬: {request.category}' if request.category else ''}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ 1-10ì  ì²™ë„ë¡œ í‰ê°€í•˜ê³  êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:

1. ì¬ë¯¸ë„ (Entertainment Value): ì‹œì²­ìì˜ í¥ë¯¸ë¥¼ ìœ ë°œí•˜ê³  ì§€ì†ì‹œí‚¬ ìˆ˜ ìˆëŠ”ê°€?
2. ì‚¬ì‹¤ì„± (Factual Accuracy): ì •ë³´ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„±ì€ ì–´ë– í•œê°€?
3. í¥ë¯¸ë„ (Engagement Level): ì‹œì²­ìê°€ ëê¹Œì§€ ë³¼ ê°€ëŠ¥ì„±ì€ ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?
4. ë…ì°½ì„± (Originality): ê¸°ì¡´ ì½˜í…ì¸ ì™€ ì°¨ë³„í™”ë˜ëŠ” ë…íŠ¹í•œ ìš”ì†Œê°€ ìˆëŠ”ê°€?
5. ì‹¤ìš©ì„± (Practical Value): ì‹œì²­ìì—ê²Œ ì‹¤ì§ˆì  ë„ì›€ì´ë‚˜ ê°€ì¹˜ë¥¼ ì œê³µí•˜ëŠ”ê°€?
6. íŠ¸ë Œë“œ ì í•©ì„± (Trend Relevance): í˜„ì¬ íŠ¸ë Œë“œì™€ ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ê°€?
7. íƒ€ê²Ÿ ëª…í™•ì„± (Target Clarity): ëª©í‘œ ì‹œì²­ìì¸µì´ ëª…í™•í•˜ê³  ê·¸ë“¤ì—ê²Œ ì í•©í•œê°€?
8. ì œì‘ ê°€ëŠ¥ì„± (Production Feasibility): ì‹¤ì œ ì œì‘ì´ í˜„ì‹¤ì ìœ¼ë¡œ ê°€ëŠ¥í•œê°€?

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "ì´í‰": "í•œ ë¬¸ì¥ ì¢…í•© í‰ê°€",
  "ì ìˆ˜": {{
    "ì¬ë¯¸ë„": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "ì‚¬ì‹¤ì„±": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "í¥ë¯¸ë„": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "ë…ì°½ì„±": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "ì‹¤ìš©ì„±": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "íŠ¸ë Œë“œ_ì í•©ì„±": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "íƒ€ê²Ÿ_ëª…í™•ì„±": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}},
    "ì œì‘_ê°€ëŠ¥ì„±": {{"ì ìˆ˜": 0, "ì´ìœ ": ""}}
  }},
  "í‰ê· _ì ìˆ˜": 0,
  "ê°•ì ": ["ê°•ì 1", "ê°•ì 2"],
  "ê°œì„ ì ": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
  "ì¶”ì²œ_ì•¡ì…˜": "êµ¬ì²´ì ì¸ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"
}}"""

        # Claude CLI ëª…ë ¹ì–´ êµ¬ì„±
        cmd = [
            "claude",
            "-p",
            prompt
        ]
        
        # í„°ë¯¸ë„ì— ìš”ì²­ ë‚´ìš© ì¶œë ¥
        print("\n" + "="*80)
        print("[Claude CLI ìš”ì²­]")
        print(f"ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"í‰ê°€ íƒ€ì…: {request.evaluation_type}")
        if request.title:
            print(f"ì œëª©: {request.title}")
        if request.category:
            print(f"ì¹´í…Œê³ ë¦¬: {request.category}")
        print(f"ì½˜í…ì¸  ê¸¸ì´: {len(request.content)} ë¬¸ì")
        print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        print("ëª…ë ¹ì–´:", ' '.join(cmd[:3]) + " [í”„ë¡¬í”„íŠ¸ ìƒëµ]")
        print("="*80)
        
        logger.info(f"Claude CLI í˜¸ì¶œ ì‹œì‘")
        
        # subprocessë¡œ Claude CLI ì‹¤í–‰
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
        )
        
        if result.returncode != 0:
            logger.error(f"Claude CLI ì˜¤ë¥˜: {result.stderr}")
            print(f"\n[ì˜¤ë¥˜] Claude CLI ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
            print("="*80 + "\n")
            raise Exception(f"Claude CLI ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
        
        # JSON íŒŒì‹±
        try:
            # Claude CLIì˜ ì¶œë ¥ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            output = result.stdout.strip()
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì½”ë“œë¸”ë¡ ì œê±°)
            if '```json' in output:
                json_start = output.find('```json') + 7
                json_end = output.find('```', json_start)
                output = output[json_start:json_end].strip()
            elif output.startswith('{'):
                pass  # ì´ë¯¸ JSON í˜•íƒœ
            else:
                # JSON ì°¾ê¸°
                json_start = output.find('{')
                json_end = output.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    output = output[json_start:json_end]
                else:
                    raise ValueError("Claude CLIê°€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            evaluation_data = json.loads(output)
            
        except (json.JSONDecodeError, KeyError, IndexError) as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            logger.error(f"ì›ë³¸ ì‘ë‹µ: {result}")
            raise Exception(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        
        processing_time = time.time() - start_time
        logger.info(f"ì½˜í…ì¸  í‰ê°€ ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
        
        # í„°ë¯¸ë„ì— ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(f"\n[ì„±ê³µ] Claude CLI ì‘ë‹µ ìˆ˜ì‹ ")
        print(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        if 'total_score' in evaluation_data or 'í‰ê· _ì ìˆ˜' in evaluation_data:
            score = evaluation_data.get('total_score') or evaluation_data.get('í‰ê· _ì ìˆ˜', 0)
            print(f"í‰ê°€ ì ìˆ˜: {score}/10")
        if 'ì´í‰' in evaluation_data:
            print(f"ì´í‰: {evaluation_data['ì´í‰']}")
        print("="*80 + "\n")
        
        # Claude CLIì˜ ì›ë³¸ í…ìŠ¤íŠ¸ ì‘ë‹µë„ í•¨ê»˜ ë°˜í™˜
        return ContentEvaluationResponse(
            success=True,
            evaluation=evaluation_data,
            processing_time=processing_time,
            result=result.stdout.strip()  # ì›ë³¸ í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶”ê°€
        )
        
    except subprocess.TimeoutExpired:
        logger.error("Claude CLI íƒ€ì„ì•„ì›ƒ")
        print(f"\n[ì˜¤ë¥˜] Claude CLI íƒ€ì„ì•„ì›ƒ (60ì´ˆ ì´ˆê³¼)")
        print("="*80 + "\n")
        return ContentEvaluationResponse(
            success=False,
            error="í‰ê°€ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.",
            processing_time=time.time() - start_time
        )
    except Exception as e:
        logger.error(f"ì½˜í…ì¸  í‰ê°€ ì‹¤íŒ¨: {str(e)}")
        print(f"\n[ì˜¤ë¥˜] ì½˜í…ì¸  í‰ê°€ ì‹¤íŒ¨: {str(e)}")
        print("="*80 + "\n")
        return ContentEvaluationResponse(
            success=False,
            error=str(e),
            processing_time=time.time() - start_time
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT) 