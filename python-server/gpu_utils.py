"""
GPU ê°ì§€ ë° ì„¤ì • ìœ í‹¸ë¦¬í‹°
Apple Silicon Macì—ì„œ ìµœì í™”ëœ Whisper ì„±ëŠ¥ì„ ìœ„í•œ ì„¤ì •
"""

import logging
import platform

logger = logging.getLogger(__name__)

def is_apple_silicon() -> bool:
    """Apple Silicon Macì¸ì§€ í™•ì¸"""
    return platform.processor() == 'arm' and platform.system() == 'Darwin'

def detect_gpu_device() -> str:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ GPU ë””ë°”ì´ìŠ¤ë¥¼ ê°ì§€í•˜ì—¬ ë°˜í™˜
    Apple Silicon Macì—ì„œëŠ” ì„¤ì •ì— ë”°ë¼ MPS ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    """
    try:
        import torch
        from constants import USE_MPS_ON_APPLE_SILICON
        
        # Apple Silicon Mac í™•ì¸
        if is_apple_silicon():
            logger.info("Apple Silicon Mac ê°ì§€ë¨")
            
            # MPS ì‚¬ìš© ì„¤ì • í™•ì¸
            if USE_MPS_ON_APPLE_SILICON:
                # Metal Performance Shaders (Apple Silicon) í™•ì¸
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    device = "mps"
                    logger.info("Metal GPU (MPS) ì‚¬ìš© ê°€ëŠ¥ - Apple Silicon ìµœì í™” ëª¨ë“œ")
                    return device
                else:
                    logger.warning("Apple Silicon Macì´ì§€ë§Œ MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            else:
                logger.info("Apple Silicon Macì—ì„œ MPS ì‚¬ìš©ì´ ë¹„í™œì„±í™”ë¨, CPU ì‚¬ìš©")
                return "cpu"
        
        # CUDA (NVIDIA GPU) í™•ì¸
        if torch.cuda.is_available():
            device = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            logger.info(f"CUDA GPU ê°ì§€ë¨: {gpu_name}")
            return device
        
        # Metal Performance Shaders (ì¼ë°˜ macOS)
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = "mps"
            logger.info("Metal GPU (MPS) ê°ì§€ë¨")
            return device
        
        # CPU ì‚¬ìš©
        else:
            device = "cpu"
            logger.info("GPU ì—†ìŒ, CPU ì‚¬ìš©")
            return device
            
    except ImportError:
        logger.warning("torch ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŒ, CPU ì‚¬ìš©")
        return "cpu"
    except Exception as e:
        logger.warning(f"GPU ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.info("CPU ì‚¬ìš©ìœ¼ë¡œ í´ë°±")
        return "cpu"

def test_mps_stability() -> bool:
    """
    MPS ë°±ì—”ë“œì˜ ì•ˆì •ì„±ì„ í…ŒìŠ¤íŠ¸
    """
    try:
        import torch
        if not (hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()):
            return False
            
        # ê¸°ë³¸ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
        test_tensor = torch.randn(2, 2, device="mps")
        result = test_tensor + test_tensor
        
        # Whisperì—ì„œ ì‚¬ìš©í•˜ëŠ” ì—°ì‚°ë“¤ í…ŒìŠ¤íŠ¸
        # 1. Float16 ì—°ì‚° í…ŒìŠ¤íŠ¸
        float16_tensor = torch.randn(1, 1, dtype=torch.float16, device="mps")
        _ = float16_tensor * 2.0
        
        # 2. ë³µì¡í•œ ì—°ì‚° í…ŒìŠ¤íŠ¸
        complex_tensor = torch.randn(10, 10, device="mps")
        _ = torch.matmul(complex_tensor, complex_tensor.T)
        
        logger.info("MPS ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except ImportError:
        logger.warning("torch ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŒ")
        return False
    except Exception as e:
        logger.warning(f"MPS ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def get_optimal_device() -> str:
    """
    ìµœì ì˜ ë””ë°”ì´ìŠ¤ë¥¼ ë°˜í™˜
    Apple Silicon Macì—ì„œëŠ” MPSë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤
    """
    from constants import ENABLE_GPU, GPU_DEVICE
    
    if not ENABLE_GPU:
        logger.info("GPU ì‚¬ìš©ì´ ë¹„í™œì„±í™”ë¨, CPU ì‚¬ìš©")
        return "cpu"
    
    if GPU_DEVICE == "auto":
        return detect_gpu_device()
    elif GPU_DEVICE in ["cuda", "mps", "cpu"]:
        # ìš”ì²­ëœ ë””ë°”ì´ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        try:
            import torch
            if GPU_DEVICE == "cuda" and not torch.cuda.is_available():
                logger.warning("CUDA ìš”ì²­ë˜ì—ˆì§€ë§Œ ì‚¬ìš© ë¶ˆê°€ëŠ¥, CPUë¡œ í´ë°±")
                return "cpu"
            elif GPU_DEVICE == "mps" and not (hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()):
                logger.warning("MPS ìš”ì²­ë˜ì—ˆì§€ë§Œ ì‚¬ìš© ë¶ˆê°€ëŠ¥, CPUë¡œ í´ë°±")
                return "cpu"
        except ImportError:
            logger.warning("torch ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŒ, CPUë¡œ í´ë°±")
            return "cpu"
        else:
            return GPU_DEVICE
    else:
        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë””ë°”ì´ìŠ¤: {GPU_DEVICE}, CPU ì‚¬ìš©")
        return "cpu"

def get_safe_device() -> str:
    """
    ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ë¥¼ ë°˜í™˜ (MPS ì˜¤ë¥˜ ì‹œ CPUë¡œ í´ë°±)
    Apple Silicon Macì—ì„œ ìµœì í™”ëœ ì²˜ë¦¬
    """
    device = get_optimal_device()
    
    # MPS ë””ë°”ì´ìŠ¤ì¸ ê²½ìš° ì•ˆì „ì„± í™•ì¸
    if device == "mps":
        if test_mps_stability():
            return device
        else:
            logger.warning("MPS ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, CPUë¡œ í´ë°±")
            return "cpu"
    
    return device

def get_device_info() -> dict:
    """
    í˜„ì¬ ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ ë°˜í™˜
    """
    # Simplified device detection for whisper.cpp Metal
    info = {
        "device": "Metal GPU (whisper.cpp)" if is_apple_silicon() else "CPU",
        "gpu_available": is_apple_silicon(),
        "gpu_name": "Apple Metal GPU (whisper.cpp)" if is_apple_silicon() else None,
        "memory_info": None,
        "platform": platform.system(),
        "processor": platform.processor(),
        "is_apple_silicon": is_apple_silicon()
    }
    
    try:
        import torch
        device = get_safe_device()
        info["device"] = device
        
        if device == "cuda":
            info["gpu_available"] = True
            info["gpu_name"] = torch.cuda.get_device_name(0)
            info["memory_info"] = {
                "total": torch.cuda.get_device_properties(0).total_memory,
                "allocated": torch.cuda.memory_allocated(0),
                "cached": torch.cuda.memory_reserved(0)
            }
        elif device == "mps":
            info["gpu_available"] = True
            info["gpu_name"] = "Apple Metal GPU (MPS)"
    except ImportError:
        # torch not available, use simplified detection
        pass
    
    return info

def log_device_info():
    """ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ ë¡œê·¸ì— ì¶œë ¥"""
    info = get_device_info()
    logger.info(f"í”Œë«í¼: {info['platform']} ({info['processor']})")
    logger.info(f"Apple Silicon: {'ì˜ˆ' if info['is_apple_silicon'] else 'ì•„ë‹ˆì˜¤'}")
    logger.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {info['device']}")
    
    if info['gpu_available']:
        logger.info(f"GPU ì´ë¦„: {info['gpu_name']}")
        if info['memory_info']:
            total_gb = info['memory_info']['total'] / (1024**3)
            allocated_gb = info['memory_info']['allocated'] / (1024**3)
            logger.info(f"GPU ë©”ëª¨ë¦¬: {allocated_gb:.2f}GB / {total_gb:.2f}GB ì‚¬ìš© ì¤‘")
    else:
        logger.info("CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘")
    
    # Apple Silicon ìµœì í™” ì •ë³´
    if info['is_apple_silicon'] and info['device'] == 'mps':
        logger.info("ğŸš€ Apple Silicon ìµœì í™” ëª¨ë“œ í™œì„±í™”")
    elif info['is_apple_silicon'] and info['device'] == 'cpu':
        logger.info("âš ï¸ Apple Silicon Macì´ì§€ë§Œ CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘") 